\documentclass[crop=false,a4paper,oneside,11pt]{standalone}
\usepackage{a4wide,graphicx,fancyhdr,amsmath,amssymb,float,graphicx,color,geometry,xcolor,titlesec,colortbl,tabu}
\usepackage[parfill]{parskip}
\usepackage[nodayofweek]{datetime}
%----------------------- Macros and Definitions --------------------------

%fast change of things
\newcommand{\mysubject}{2IO70 DBL Embedded Systems}
\newcommand{\myassignment}{Group 12}

%\definecolor{titlepagecolor}{cmyk}{1,.60,0,.40}
%\definecolor{namecolor}{cmyk}{1,.50,0,.10}


\setlength\headheight{20pt}
\addtolength\topmargin{-10pt}
\addtolength\footskip{20pt}

% Define light and dark Microsoft blue colours
\definecolor{MSBlue}{rgb}{.204,.353,.541}
\definecolor{MSLightBlue}{rgb}{.31,.506,.741}
\arrayrulecolor{MSLightBlue}

% Set formats for each heading level

\titleformat*{\section}{\Large\bfseries\sffamily\color{MSBlue}}
\titleformat*{\subsection}{\large\bfseries\sffamily\color{MSLightBlue}}

%date format
\newdateformat{mydate}{\monthname[\THEMONTH] \THEYEAR}

\fancypagestyle{plain}{%
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
}

\pagestyle{fancy}
\fancyhf{}
\fancyfoot[CO] {\thepage}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}


%--------------------------------- Text ----------------------------------
\setcounter{secnumdepth}{0}
\begin{document}

\section{Experimental Evaluation}

We ran all the tests in our experimental evaluation on a HP EliteBook 8570w with an Intel i7-3630QM CPU @ 2.40GHz and 8.00 GB RAM. To measure the amount of time the algorithm takes to complete, we start a timer in the code just before the part we want to test and we stop the timer right after the algorithm terminates. For testing the 2-position, 4-position and 1-slider algorithms we generated test cases with $5$ different distributions. We are using different type of distributions in order to see how our algorithm works in different situations including when points are placed uniformly or placed closely. These distributions are:
\begin{enumerate}
    \item Uniform. Points are randomly placed on a $10000$ by $10000$ plane.
    \item Clustered. Points are placed closely around $20$ randomly chosen points.
    \item H Clustered. Points are placed in horizontal strips around $10$ randomly chosen $y$-coordinates.
    \item V Clustered. Points are placed in vertical strips around $10$ randomly chosen $x$-coordinates.
    \item Bounded. Points are randomly placed on a $1000$ by $1000$ plane.
\end{enumerate}

\subsection{2-position}
\subsubsection{Results}
The algorithm for the 2-position model is explained in detail in section 2.2. As a short recap, this algorithm has two phases: first we map all the collisions of every candidates of every single point, then we try to place the candidates that have least amount of collisions. A visual explanation of the 2-position model can be found in figure 1.\\
For the experimental evaluation of the 2-position algorithm we used $2500$ different test cases with $500$ cases for each distribution. These test cases start with 100 points and increase by 100 points until it reaches 10000 points. The running times of the test cases can be found in figure 2 and the percentage of points the algorithm could label can be found in figure 3.\\

\begin{figure}[H]
 \centering
  \centerline{\includegraphics[scale = 0.5]{2PosRunningTime.png}}
  \caption{The running time of the 2-position algorithm}
 \end{figure}

\begin{figure}[H]
 \centering
  \centerline{\includegraphics[scale = 0.5]{2PosLabelsPlaced.png}}
  \caption{The percentage of labels placed by the 2-position algorithm}
 \end{figure}

\subsubsection{Discussion}
As stated in section 2.2.1 the theoretical running time of the 2-position algorithm is $O(n^2)$. From figure 2 we can see that the running time of most of the cases are quite low. They take less than 10000 milliseconds to place all the labels. This is because the amount of collisions of the candidates is small, so it will not take much time to map the collisions and it will take even less time to place the labels. There are some cases that have higher running time than the others. We can see from the figure that the practical worst case running times are close to the theoretical running time $O(n^2)$. The running time in practice thus seems to be between $O(n)$ and $O(n^2)$ \\
The worst cases of each distribution suddenly drop when the number of points reaches a specific amount(around 7000 for bounded cases and around 8000 for the others). This is because in these cases, there are many collisions. If we use the regular algorithm, the running time will go over 5 minutes, so in that case, we use a greedy algorithm to place the labels.\\
Other than the running time, we also look at the amount labels our algorithm placed. As we can see from figure 3, when the amount of points is small, the algorithm gives solutions with a high percentage of placed labels. For uniform cases and clustered cases, our algorithm gives a high solution, and for most of the cases except for bounded cases, it also give solutions that are higher than ten percent. Hence, based on our observation, our algorithm is close to optimal solution. When the amount of points become higher, the percentage of placed labels will become lower. This is what we expected as the labels have the same height and the same width for the same type of distribution but with a higher amount of points. Uniform cases and clustered cases have higher solution than the others in most cases. The reason why bounded cases have low solution is because all points are placed in a small area and this causes there to be more overlaps for the candidates.\\
As this algorithm is considered very fast and gives a result that is quiet optimal, we consider this algorithm as the optimal solution for this problem.\\


\subsection{4-position}
\subsubsection{Results}
The algorithm of the 4-position model is explained in full detail in section 2.2. It is similar to the algorithm for the 2-position model, except it has two more possible label candidates. A visual explanation of the 4-position model can be seen in figure 1.\\
 For the experimental evaluation of the 4-position algorithm we also used $2500$ different test cases with $500$ cases for each distribution. These test cases start with 100 points and increase by 100 points until it reaches 10000 points. The running times of the test cases can be found in figure 4 and the percentage of points the algorithm could label can be found in figure 5.\\

 \begin{figure}[H]
 \centering
 \centerline{\includegraphics[scale = 0.5]{4PosRunningTime.png}}
 \caption{The Running Time of the 4-position algorithm}
 \end{figure}

 \begin{figure}[H]
 \centering
  \centerline{\includegraphics[scale = 0.5]{4PosLabelsPlaced.png}}
  \caption{The percentage of labels placed by the 4-position algorithm}
 \end{figure}

\subsubsection{Discussion}
As we stated in section 2.2.1, the algorithm for the 4-position model is nearly the same as the algorithm for the 2-position model. Hence the theoretical running time of the 4-position algorithm is also $O(n^2)$. In figure 4, it shows the running time of $2500$ different cases. As with the algorithm for the 2-position model, the running time for most of the cases is close to a more linear running time of $O(n)$. This is because the amount of collisions of the candidates is small, so it will not take much time to map the collisions and it will take less time to place the labels. We can see from the figure that the practical worst-case running time is close to the theoretical running time $O(n^2)$. The running time in practice thus seems to be between $O(n)$ and $O(n^2)$  \\
The running time of the worst cases of each distribution also suddenly drop when the number of points reaches a specific amount(around 4000 points foe all cases). This is because, in these cases, there are too many collisions and, as with the 2-position algorithm, we use a greedy algorithm to place the labels. However, there are still some differences between the algorithm for the 2-position model and the 4-position model. The 4-position algorithm reverts to using the greedy algorithm faster than 2-position algorithm. This is because, with the 4-position model, more collisions occur between candidates as there are more possible positions for a candidate to be in.\\
Other than running time, we also look at the amount of placed labels of our algorithm. As we can see from figure 5, when the amount of points is small, the algorithm gives solutions with a high percentage of placed labels. When the amount of points become higher, the percentage of placed labels will become lower. This can be explained by the same situation in 2-position model. For uniform cases and clustered cases, our algorithm gives a high solution, and for most of the cases except for bounded cases, it also give solutions that are higher than ten percent. Hence, based on our observation, our algorithm for 4-position model is also close to optimal solution. As the same as in 2-position algorithm, uniform cases and clustered cases have higher solution than the others in most cases. Bounded cases have low solution. Compared to the result of 2-position algorithm, 4-position algorithm has higher solution in the percentage of placed labels since every point has two more candidates it can place.\\
As this algorithm is also considered very fast and always gives an optimal result, we consider this algorithm as the optimal solution for this problem.\\


\subsection{1-slider}
\subsubsection{Results}
For the evaluation of the 1-slider algorithm we ran 500 test cases, 100 for each distribution. These test cases start with 500 points and increase by 500 points until it reaches 10000 points. We won't use the same amount of cases as with 2-position and 4-position, because it will take too much time run 2500 cases and we don't have enough time for that. The 1-slider algorithm is explained in full detail in section 2.3. An example of the 1-slider model can be found in figure 1.\\
 The running times of the test cases can be found in figure 6 and the percentage of points the algorithm could label can be found in figure 7.

 \begin{figure}[H]
 \centering
 \centerline{\includegraphics[scale = 0.65]{1slider.png}}
 \caption{The running time of the 1-slider algorithm}
 \end{figure}

 \begin{figure}[H]
 \centering
  \centerline{\includegraphics[scale = 0.65]{1sliderplaced.png}}
  \caption{The percentage of labels placed by the 1-slider algorithm}
 \end{figure}

\subsubsection{Discussion}
From section 2.3.9 we find that the theoretical running time of the 1-slider algorithm is $O(n^3)$. From figure 6 we can see that the practical running time of the 500 test cases matches the theoretical running time. The figure also shows that the running time of all the test cases plateaus after a certain amount of points is reached. This is because after 4.5 minutes has been reached we stop the algorithm and report the best solution found until then. From testing we found that ending the algorithm after 4.5 minutes left enough time for the algorithm to terminate and return the solution it had found such that it did not run longer than 5 minutes.\\
In figure 7 we can see the percentage of points that have been assigned a label. As usual, the amount of points that could be labelled decreases as the amount of points increases with the bounded test cases being affected the most. When we compare the results to the 2-position algorithm in figure 3, we see that the 1-slider manages to place slightly more labels. However, when we compare the results of the 1-slider to the results of the 4-position in figure 5, we can see that it manages to place considerably less labels. This is because the 1-slider can not place labels under points, while the 4-position algorithm can.
Although this algorithm takes quiet a long time but it gives an optimal result, so we consider this algorithm as our optimal solution for this problem.\\

\end{document}
