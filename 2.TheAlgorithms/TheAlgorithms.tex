\documentclass[crop=false,a4paper,oneside,11pt]{article}
\usepackage{a4wide,graphicx,fancyhdr,amsmath,amssymb,float,graphicx,color,geometry,xcolor,titlesec,colortbl,tabu}
\usepackage[parfill]{parskip}
\usepackage[nodayofweek]{datetime}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{float}
%----------------------- Macros and Definitions --------------------------

%fast change of things
\newcommand{\mysubject}{2IO90 DBL Algorithms}
\newcommand{\myassignment}{Group 4}

%\definecolor{titlepagecolor}{cmyk}{1,.60,0,.40}
%\definecolor{namecolor}{cmyk}{1,.50,0,.10}


\setlength\headheight{20pt}
\addtolength\topmargin{-10pt}
\addtolength\footskip{20pt}

% Define light and dark Microsoft blue colours
\definecolor{MSBlue}{rgb}{.204,.353,.541}
\definecolor{MSLightBlue}{rgb}{.31,.506,.741}
\arrayrulecolor{MSLightBlue}

% Set formats for each heading level

\titleformat*{\section}{\Large\bfseries\sffamily\color{MSBlue}}
\titleformat*{\subsection}{\large\bfseries\sffamily\color{MSLightBlue}}

%date format
\newdateformat{mydate}{\monthname[\THEMONTH] \THEYEAR}

\fancypagestyle{plain}{%
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
}

\pagestyle{fancy}
\fancyhf{}
\fancyfoot[CO] {\thepage}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

%--------------------------------- Text ----------------------------------
\setcounter{secnumdepth}{0}
\begin{document}
\section{The Algorithms}
In this section we will describe the algorithms we use for each of the placement models.\\
All our algorithms use a quadtree to quickly find all points in an interval. This will be described first. Furthermore, the algorithms for the 2pos model and the 4pos model are very similar, these will be discussed together. After that, we will describe the algorithm for the 1slider model.

\subsection{Quadtree}

Since advanced label-placing algorithms have a tendency of requesting information about what labels exist in a certain area, a quadtree can help speed up those algorithms. A quadtree is defined as a tree, with a node having four children recursively. Each node of the tree stores information about a certain square-shaped area it bounds, including an array of points which have their location in the area of that node. Nodes which contain points are leaves of the tree. The four child nodes are the subdivision of its parent node. This means that nodes in a certain area can be easily found by traversing the tree.\\
Since every point is distinct, and there are only $10000 * 10000$ possible placements, we can reasonably assume the tree is balanced.\\
\begin{algorithm}[H]
\caption{Add label to the quadtree}
\begin{algorithmic}[1]
\Procedure{AddLabel}{$Label\ l$}
\If{$this.children.size > 0$}\Comment{Here we traverse the tree}
\For{$c \in this.children$}
\If{$Overlap(l.pos, c.area)$}
\State $c.AddLabel(l)$
\EndIf
\EndFor
\Else\Comment{Here add the label to the node}
\State $this.add(l)$
\If{$this.labels.size>maxNodeSize$}
\State $this.split()$ \Comment{Split the node into 4 subnodes}
\EndIf
\EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}
In a balanced quadtree the maximum depth is in $O(\log{n})$, which means our algorithm also runs in $O(\log{n}))$


Here we will show how a quadtree can be used to find labels in a certain area.\\
\begin{algorithm}[H]
\caption{Find labels in an area}
\begin{algorithmic}[1]
\Procedure{LabelsInArea}{$Area\ a$}
\State $out = \emptyset$
\If{$this.children.size > 0$}\Comment{Here we traverse the tree}
\For{$c \in this.children$}
\If{$Overlap(a, c.area)$}
\State $out.add(c.LabelsInArea())$
\EndIf
\EndFor
\Else\Comment{Here we return the right labels}
\For{$l \in this.labels$}
\If{$a.contains(l.pos)$}
\State $out.add(l)$
\EndIf
\EndFor
\EndIf
\State \textbf{return} $out$
\EndProcedure
\end{algorithmic}
\end{algorithm}

When dealing with a balanced quadtree with $n$ labels, the worst-case running time is $O(n)$, which is when the labelsInArea method returns all labels. In the worst case scenario, the tree would be traversed for every node. Since we assumed the quadtree to be balanced, there are $O(n)$ nodes, and there are $n$ labels, therefore the running time is in $O(n)$.

\subsection{2-position model and 4-position model}
For the 2-position model and the 4-position model we use a very simple approach. We will first our algorithm. While doing this we will also derive the theoretical running times. Then we will prove that it does not place overlapping labels. After that we will prove this approach applies the rules L1, L2 and L3 (from Automated Label Placement in Theory and Practice, by Alexander Wolff) correctly.

\subsubsection{Description of the algorithm}
Our algorithm is simple but also very efficient. It has two phases:
\begin{enumerate}
\item \textbf{Phase 1: Mapping the collisions}\\
It checks for every candidate (a candidate is a possible placement of a label for a point) with which candidates it intersects. For each candidate, we store every candidate it collides with in an arraylist, the so-called CollisionList of a candidate. We find these collisions using the quad tree. When we have these collisions, we store all candidates in a MinHeap. The nodes are the candidates and the keys are their number of collisions (plus 0.25 times the number of candidates its point has). Using this data structure is very useful later on, when we want to extract the minimum very often and change keys of nodes even more frequently.
\item \textbf{Phase 2: Placing candidates}\\
It may be shocking how easy our actual approach is: we find the candidate with the least amount of collisions (with the MinHeap) and we place it. We place a candidate using the Place function. This function takes a candidate $c$ as argument. It will do the following: It will eliminate all the candidates of the point of which $c$ is a candidate and it will also eliminate all the candidates that $c$ collides with (every candidate in $c$'s CollisionList). This eliminating will be done using an Eliminate function. This function takes a candidate $c$ as argument and it will remove $c$ from all the CollisionLists for all candidates $c^*$ in the CollisionList of $c$. It will also remove $c$ from the MinHeap. In this way, later on will not have to look after candidates that are already placed or are eliminated. 
\end{enumerate}
Below you can see the pseudo-code for the algorithms. First we will show the main algorithm and then we will show the smaller functions, such as the Place and Eliminate function.

\begin{algorithm}[H]
\caption{Main Algorithm}
\begin{algorithmic}[1]
\Procedure{K-Pos-Algorithm}{}\Comment{Can be used for 2pos, 4pos or any k-pos model}
\State Initialize the solution $S$ to the empty set
\State Insert all points in the quad tree $q$
\State Give points their candidates
\For{$c\in$Candidates}\Comment{For each point we will find its collisions}
\State $c.CollisionList\gets$ GiveCollisions($c$)
\EndFor
\State Create a MinHeap $h$ containing all the candidates
\While{$H$ is not empty}
\State $S\gets S\cup \{h.$minimum$\}$\Comment{Add the candidate with the least collisions to the solution}
\State Place($h$.Minimum)\Comment{We place this minimum}
\EndWhile
\State \textbf{return} $S$\Comment{$S$ is our solution, we will return it}
\EndProcedure
\end{algorithmic}
\end{algorithm}
\textbf{Running time}\\
The first line takes $\Theta(1)$ of course, the second line will take $\Theta(n\log n)$ since it inserts (insertion takes $\Theta(\log n)$) $n$ points. For the third line it has to give $n$ points $k$ candidates. Giving a point a candidate takes $\Theta(1)$. In the case of the 4-position and the 2-position model, $k$ equals 4 and 2 respectively. So this line will take $\Theta(n)$. Now there is the for-loop. This loops over all $\Theta(n)$ candidates and gives it its collisions. The latter takes $\Theta(n)$ as described below. Now we create a MinHeap, creating a Heap takes $\Theta(n)$. After that, there is a while-loop. Inside this while-loop we place candidates untill the heap is empty. Placing candidates will result in at least one elimination. Every candidate can only be eliminated once and the elimination takes $\Theta(n)$ as described later on. Concluding, the whole algorithm takes $\Theta(1)+\Theta(n\log n)+\Theta(n)+\Theta(n)*\Theta(n)+\Theta(n)+\Theta(n)*\Theta(n)=\Theta(n^2)$.

\begin{algorithm}[H]
\caption{The algorithm that returns the colliding candidates of a candidate $c$}
\begin{algorithmic}[1]
\Procedure{GiveCollisions}{Candidate $c$}
\State Initialize the CollisionsList $C$ to the empty set
\State PossibleCollisions$\gets q$.LabelInArea($c$)\Comment{This will return all points that can have an intersecting candidate}
\For{$p\in$PossibleCollisions}\Comment{We go through all these points}
\For{each candidate $c_p$ of $p$}
\If{$c_p$ intersects $c$}
\State add $c_p$ to $C$
\EndIf
\EndFor
\EndFor
\State \textbf{return} $C$\Comment{$C$ now contains all the candidates that collide with $c$}
\EndProcedure
\end{algorithmic}
\end{algorithm}
\textbf{Running time}\\
The first statement takes $\Theta(1)$. The second statement uses the LabelsInArea function, this has running time $\Theta(n)$. So this results in $\Theta(n)$. Then there is the loop going through all these $\Theta(n)$ points. Inside this loop it checks for each candidate of the point (this number of candidates is $\Theta(1)$) whether it intersects with $c$, this takes $\Theta(1)$. Adding it also takes $\Theta(1)$. So concluding: The running time of this procedure is $\Theta(1)+\Theta(n)+\Theta(n)*\Theta(1)*(\Theta(1)+\Theta(1))=\Theta(n)$.

\begin{algorithm}[H]
\caption{The algorithm that places a candidate $c$}
\begin{algorithmic}[1]
\Procedure{Place}{Candidate $c$}
\For{Every candidate $c_p$ of the point of $c$}
\State Eliminate($c_p$)\Comment{Eleminate all candidates of the point that we place}
\EndFor
\For{$c_c\in c.$CollisionList}
\State Eliminate($c_c$)\Comment{Also eliminate all candidates that collide with the candidate we are placing}
\EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}
\textbf{Running time}\\
There are two loops in this procedure. The first loops over all the candidates $C_p$ of the point $p$ of $c$. So 4 for the 4-position model and 2 for the 2-position model. $\Theta(1)$ either way. In this loop it performs the Eliminate function, this will take $\Theta(\log n + n^*)$ ($n^*$ is the number of collisions of the candidate we are eliminating) as you can see below. The second loop loops over all the candidates in the CollisionList $L_c$ of $c$, we will call the number of colliding candidates $n_c$. Inside this loop, we perform Eliminate again, this again takes $\Theta(\log n + n^*)$ every time. So we get:
$$\sum\limits_{i=1}^k(\log n + n_{C_p[i]})+\sum\limits_{i=1}^{n_c}(\log n + n_{L_c[i]})=\Theta((k+n_c)(\log n))+n_{cc}$$
Here $n_{cc}$ denotes the amount of candidates that collide with a candidate that collide with $c$. Unfortunately, $n_{cc}$ is $\Theta(n^2)$ is the worst case, $n_{L_c[i]}=\Theta(n)$ and $n_c=\Theta(n)$ as well. Fortunately, $k=\Theta(1)$ in the case of the 4pos and 2pos model. So we end up with $\Theta(n^2)$.

\begin{algorithm}[H]
\caption{The algorithm that eliminates a candidate $c$}
\begin{algorithmic}[1]
\Procedure{Eliminate}{Candidate $c$}
\For{$c_c\in c.$CollisionList}
\State Remove $c$ from $c_c.$CollisionList \Comment{let $c_c$ know it does not have to look after $c$ anymore}
\EndFor
\State remove $c$ from the MinHeap
\EndProcedure
\end{algorithmic}
\end{algorithm}
\textbf{Running time}\\
As you can see there is one loop in this procedure. This loop loops over all collisions of $c$, we will call this $n_c$. Removing the candidate from the CollisionList takes $\Theta(1)$. Furthermore, removing a node from a MinHeap takes $\Theta(\log n)$ of course. Concluding: The whole procedure takes $\Theta(n_c)*\Theta(1)+\Theta(\log n)=\Theta(\log n + n_c)$

\subsubsection{Proof of no overlapping labels}
We will prove the correctness (no intersections) of our algorithms using a loop invariant over the while-loop in the main algorithm:

\textbf{Loop invariant:} $S$ does not contain overlapping candidates. Furthermore, there is no candidate $c_s\in S$ that collides with a candidate $c_h$ in the heap.

\textbf{Initialization:} $S$ is empty initially, so there are no two candidates that overlap each other and there is also no candidate in $S$ that overlaps any of the candidates in the heap.

\textbf{Maintenance:} In every iteration of the while-loop, exactly one candidate $c_m$ is added to $S$. Because of the loop invariant, it has no intersections with any of the candidates that were already in $S$. This proves the maintenance of the first part of the loop invariant. When placing the candidate, we eliminate itself and all its collisions. Calling the Eliminate function on a candidate $c$ will remove $c$ from the MinHeap. So all candidates in the Heap that collide with $c_m$ will be removed from the Heap. This together with the second part of the loop invariant (no candidate $c_s\in S$ collides with a candidate $c_h$ in the heap) proves the maintenance of the second part of the loop invariant.

\textbf{Termination:} When the loop is finished, our loop invariant proves that there are no intersecting candidates in $S$.

\subsubsection{Proof of correctly applying the rules}
Our algorithm may look too simple. But in its simplicity lies its elegance. We wanted an algorithm that could place labels efficiently in unclustered areas (using the rules) and also could give a reasonably good solution for clustered areas. This both is done by this very simple approach. Below we will prove that this applies the rules correctly.\\
\\
\textbf{Rule L1}\\
L1 applies if some $p$ has a candidate $p_i$ without any overlaps. We simply place $p_i$ and eliminate all other candidates of $p$.\\
\\
We will prove that our algorithm places a label for $p$ when L1 occurs. For the sake of contradiction, we will assume no label for $p$ is placed after termination. After termination, the heap is empty. So $p_i$ must have been removed from the heap. This only occurs when a candidate of $p$ has been placed (which we assumed is not the case) or when a label has been placed that overlaps $p_i$. The latter cannot happen since $p_i$ has no overlaps. So by contradiction it is proven that if L1 applies for some point $p$, our algorithm will label it.\\
\\
\textbf{Rule L2}\\
L2 applies if some $p$ has a candidate $p_i$ that only overlaps some $q_k$, and $q$ has a
candidate $q_j$ ($j \neq k$) that is only overlapped by $p_l$ ($l \neq i$). Then add $p_i$
and $q_j$ to the solution and eliminate all other candidates of $p$ and $q$.\\
\\
We will prove that if L2 applies for some points $p$ and $q$, our algorithm will label both $p$ and $q$. We will again prove this by contradiction. We assume that either $p$ is not labeled or that $q$ is not labeled (or both). Without loss of generallity, we can assume that $p$ is not labeled. This means that $p_i$ is removed from the heap. Since $p$ has not been placed, a candidate overlapping $p_i$ must have been placed. Since $q_k$ is the only candidate overlapping $p_i$, $q_k$ must have been placed. Since $q_j$ has one collision and we place the minimum, $q_k$ must also have one collision. Now all other candidates of $q$ will be eliminated.\\
\\
\textbf{Rule L3}\\
L3 applies if some point $p$ only has one candidate $p_i$ left and all candidates that intersect with $p$ form a clique. If this is the case, we place $p_i$ and eliminate all its collisions.\\
\\
We will prove that if L3 applies for some point $p$ with candidate $p_i$, then $p_i$ will only be eliminated by applying L3. We will assume $p_i$ is eliminated and then we will prove that L3 has been applied. Since $p_i$ is the only candidate of $p$, it can only be eliminated when placing a colliding candidate $q_j$. Since we place the candidate with the lowest key, the key of $q_j$ must be less or equal to the key of $p_i$. $p_i$ and $q_j$ have the same number of collisions since they are in the same clique so $q$ must have a number of candidates less or equal to that of $p$. $q$ cannot have zero candidates since this would mean there is no $q_j$ so $q$ must have exactly one candidate. This means L3 applied on $q$ and so it is proven that our algorithm correctly applies L3.

\subsection{1-slider model}
% new stuff about L1:
\subsubsection{Summary}
The 1-slider algorithm also uses a quadtree and a heap. It firstly initializes this quadtree, filling it with all of the points in the input. Then, each of the points will be assigned a so-called $bounding\ box$, which represent all potential label placements. These $bounding \ boxes$ will be given collision values by the quadtree. After this, a maxheap of points is initialized, using the amount of collisions the $bounding \ box$ of the point has with other $bounding \ boxes$ as keys. Now the program will enter a loop. In this loop, we find a solution for all of the points which have not been $discarded$. Firstly, we have to re-assign collision values for all of the remaining points. Secondly, we apply rule L1 and L2, which have been explained earlier. Thirdly, we finish the solution by executing a greedy algorithm on the remaining points. Lastly, we check whether the solution we found this iteration is better than the best solution so far. If it is better, we replace the best solution with this new solution. Now we delete the point of which the $bounding \ box$ has the most collisions from the heap and mark the corresponding point in the quadtree as $discarded$. This loop is repeated until the heap is empty, we have found a solution which places labels on all of the points, or when four and a half minutes have passed. In the end, we report the best solution found. A detailed explanation of all sub-algorithms and concepts is given below. \\
 \begin{algorithm}[H]
\caption{1slider algorithm}
\begin{algorithmic}[1]
\Procedure{OneSlider}{}
\State mostfound = 0
\State bestsolution = empty array of points
\State initialize timer
\State build quadtree containing all of the points
\State give collisions to all of the bounding boxes on the points
\State build heap of points with number of potential collisions as keys
\While{heap not empty \textbf{AND} timer $<$ time limit \textbf{AND} mostfound != amount of points in input}
\State give collisions to the bounding boxes of the undiscarded points
\State try L1 for each unplaced and undiscarded point
\State try L2 for each unplaced and undiscarded point
\State do the greedy part for each unplaced and undiscarded point
\State do the greedy part for all unplaced points (including discarded)
\State delete root of the heap and mark corresponding point in quadtree as discarded
\If {amount of labels placed this iteration $>$ mostfound}
\State mostfound = amount of labels placed this iteration
\State bestsolution = solution found this iteration
\EndIf
\EndWhile
\State \textbf{return} bestsolution
\EndProcedure
\end{algorithmic}
\end{algorithm}
\subsubsection{Bounding Boxes}
As mentioned earlier, $bounding \ boxes$ represent the outer-most bounds for a label when considering all possible placements using the 1-slider model. Every point $p$ is assigned such a $bounding \ box$. On the y-axis, the starting point of the bounding box will be the y-coordinate $p_y$ of the point. The length of the interval will be the label height, so the interval ends in $p_y + labelheight$. On the x-axis, the interval will start at $p_x - labelwidth$ and end at $p_x+labelwidth$. In this way, the $bounding \ box$ will precisely be the rectangle which represents all possible placements of the label. Every $bounding \ box$ $B$ also has a reference to its original point $p$ and a list of $bounding \ boxes$ it intersects with. This list is created by using the function $GiveCollisions$ in the Quadtree, which was explained earlier. Now that we have these lists, we can go through all $bounding \ boxes$ and give each $bounding \ box$ two collision values, $x_1$ and $x_2$. $x_1$ represents the x-coordinate for which the area to the left of $x_1$ contains collisions with other $bounding \ boxes$ to the left. $x_2$ represents the x-coordinate for which the area to the right of $x_2$ contains collisions with other $bounding \ boxes$ to the right. 
\subsubsection{Giving collisions}
The routine for giving collisions is executed by the quadtree. For each of the points $p$ this function is called on, it checks whether there is a point in an area around it. The area it checks is the xy-area $[p_x - 2*labelwidth, p_x + 2*labelwidth]$ x $[p_y - labelheight, p_y + labelheight]$, using the LabelsInArea function of the quadtree. The $bounding \ box$ of the point $p$ collides with the $bounding \ boxes$ of all points in the searched area. This is because points $q$ to the left of $p$ will have $bounding \ boxes$ with right bound $q_x + labelwidth$ and $p$ has left bound $p_x - labelwidth$. If the right bound of $q$ is bigger than the left bound of $p$, so if $q_x + labelwidth > p_x - labelwidth$, then the $bounding \ boxes$ collide. We can rewrite this to $q_x > p_x - 2*labelwidth$, which was the left bound of the x-interval we searched. The other three bounds, to the right, up, and down, work analogously. For each $bounding \ box$ $B$, we put all the $bounding \ boxes$ we find in the list of collisions of $B$. With these lists, we can determine $x_1$ and $x_2$ for each $B$. We do this by initially assigning the left bound of the $B$ as $B_{x_1}$ and the right bound of the $B$ as $B_{x_2}$. After that, we compare the right bound of each $bounding \ box$ in the list of collisions of $B$ to the left of $B$. If this right bound is bigger than $B_{x_1}$, then we make $B_{x_1}$ this new bound, and symmetrically the same with $B_{x_2}$. 
\subsubsection{The heap}
Beside the quadtree, the algorithm also uses a maxheap to store the points. The keys in the maxheap are the amount of collisions the $bounding \ boxes$ of the points have with other $bounding \ boxes$. This way, we can easily remove the point of which the $bounding \ box$ has the most collisions with other $bounding \ boxes$: we simply extract the root of the maxheap in $\Theta(log (k))$ time, with $k$ being the amount of points left in the heap. 
\subsubsection{Rule L1}
We will now explain how rule L1 is implemented in the 1slider algorithm. Recall that L1 places all labels which can not possibly have any intersections with other labels. We implement this by comparing the found collision values $x_1$ and $x_2$ for each $bounding \ box$ $B$ of each point $p$. If there is enough space in between $x_1$ and $x_2$ to place a label, so if $x_2 - x_1 \geq labelwidth$, then we can be sure that we can place a label there without it ever intersecting any other possible label placement. This is because $x_1$ is the right-most position for which there are collisions to the left with $bounding \ boxes$ to the left and $x_2$ is the left-most position for which there are collisions to the right with $bounding \ boxes$ to the right. This means that there are no collisions to the right of $x_1$ until we reach $x_2$ and no collisions to the left of $x_2$ until we reach $x_1$. Therefore, there are no possible overlaps in between $x_1$ and $x_2$ and we can place a label there which satisfies L1. We place the label on $p$ with slider value $\frac{p_x - B_{x_1}}{labelwidth} + 1$. This places it with the left bound of the label at x-position $B_{x_1}$. Since $x_2 - x_1 \geq labelwidth$, the right bound of the label will be $x_1 + labelwidth \leq x_2$, so the label will be in between $x_1$ and $x_2$.

\subsubsection{Rule L2}
After L1 is applied, rule L2 is executed. Recall that L2 places labels on two points which have candidates which only collide with each other. To do this, we search for points with $bounding \ boxes$ which have only one collision. We then check whether the $bounding \ boxes$ they collide with also have only one collision. If that is the case, we can say that both $bounding \ boxes$ only have one collision and we have a case of L2. We call the left-most point in this situation $p_1$ and the right-most point $p_2$. If the points have equal x-positions, this is assigned randomly. For each of these cases, we give $p_1$ slider value 0 and the $p_2$ slider value 1. This way, $p_1$ gets a label which is placed all the way to the left and the $p_2$ gets a label which is placed all the way to the right. The two labels will never intersect any labels. They will not intersect each other, because the label on $p_1$ will occupy the x-interval $[p_{1_x} - labelwidth$, $p_{1_x}]$ and the label on $p_2$ will occupy the x-interval $[p_{2_x}, p_{2_x} + labelwidth]$. Since $p_{1_x} \leq p_{2_x}$, the labels will never intersect each other. The labels will also never intersect labels outside of the L2 case, because the $bounding \ boxes$ of these points only collide with each other, so they can not intersect other potential label placements.
\subsubsection{Greedy part}
After L1 and L2, we complete the solution by executing a greedy part on the remaining points. Firstly, we do this for all undiscarded points and then we see if there are any discarded points on which we can still place a label.

\subsubsection{Reason for deleting the point with most collisions}

\subsubsection{Running time}
The running time of this algorithm is dependent on the amount of points $n$ in the input and the total amount of collisions $c$ the $bounding \ boxes$ have. For example, if we find no collisions at all, we have $n$ cases of L1 and the algorithm terminates after the first iteration of the main loop, reporting a solution which places labels on all points. Therefore, the running time of the algorithm will be described in terms of $n$ and $c$. \\
Initializing the quadtree simply adds every point in the input to the quadtree. Adding a point to the quatree takes $\Theta(log(n))$ time, so adding every point will take $\Theta(n*log(n))$ time. Initializing the heap with all of the points takes $\Theta(n)$ time. The time it takes to give collisions to the $bounding \ boxes$ will depend on the amount of points, the size of the labels, and the point distribution. We check  every point, so this gives us a multiplication factor of $n$. When checking every point, we use the function AllPointsInArea of the quadtree. The worst case running time of this function is $\Theta(n)$. The other things we do in this part all depend on how many collisions this function has found, but they take constant time, so the total running time of this part will be $\Theta(n)*\Theta(n)*\Theta(1) = \Theta(n^2)$.
  \\ \\
Now the algorithm enters the loop. This loop is repeated until the heap is empty, a solution which places labels on all of the points is found, or four and a half minutes have passed. It is nearly impossible to predict when our algorithm will find a solution which places labels on all of the points, so we will not consider this in the running time. Therefore, the total running time of the loop will be the minimum of the time it takes to empty the heap and 4.5 minutes. Firstly, we will determine the time it takes to empty the heap. At the first iteration, the heap contains $n$ points. At the end of each iteration, one point is removed from the heap. Therefore, the loop is repeated $n$ times. Inside the loop, the running time depends on the running time of assinging the collisions, applying L1, applying L2, and executing the greedy part. Most of these steps only use the points which have not been discarded. We will denote this remaining amount of points with $k$. \\ The L1 algorithm checks for every point whether the $bounding \ box$ of that point has enough space in between $x_1$ and $x_2$, and then has the possibility to place a label. These operations take constant time, so the total time it takes to apply L1 is $\Theta(k)$. \\
The L2 algorithm finds all points of which the $bounding \ box$ has only one collision. In the worst case, all of the $bounding \ boxes$ have this, and the algorithm needs to place labels on all of the points. Checking points takes $\Theta(k)$ time. We only do constant time operations every check, so the total time for L2 is $\Theta(k)$. \\
The greedy part will first execute on the points which have not been discarded and then again for all of the discarded points. This means that combined, it will execute on $n$ points every iteration.  
\\
So, we execute a loop $n$ times, in which the running times depend on a variable $k$ which runs down from $n$ to 1. The highest rate of growth in the loop is $k^2$. This gives a summation like $\sum_{k=0}^n \Theta(k^2)$, which is equal to $\Theta(n^3)$. We also have a part which takes $\Theta(n^2)$. Repeating this $n$ times gives a running time of $\Theta(n^3)$.
The total running time of the complete 1slider algorithm will therefore be $\Theta(n^3) + \Theta(n^3) = \Theta(n^3)$.
\end{document} 