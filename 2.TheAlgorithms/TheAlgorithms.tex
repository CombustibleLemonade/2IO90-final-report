\documentclass[crop=false,a4paper,oneside,11pt]{article}
\usepackage{a4wide,graphicx,fancyhdr,amsmath,amssymb,float,graphicx,color,geometry,xcolor,titlesec,colortbl,tabu}
\usepackage[parfill]{parskip}
\usepackage[nodayofweek]{datetime}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{float}
%----------------------- Macros and Definitions --------------------------

%fast change of things
\newcommand{\mysubject}{2IO90 DBL Algorithms}
\newcommand{\myassignment}{Group 4}

%\definecolor{titlepagecolor}{cmyk}{1,.60,0,.40}
%\definecolor{namecolor}{cmyk}{1,.50,0,.10}


\setlength\headheight{20pt}
\addtolength\topmargin{-10pt}
\addtolength\footskip{20pt}

% Define light and dark Microsoft blue colours
\definecolor{MSBlue}{rgb}{.204,.353,.541}
\definecolor{MSLightBlue}{rgb}{.31,.506,.741}
\arrayrulecolor{MSLightBlue}

% Set formats for each heading level

\titleformat*{\section}{\Large\bfseries\sffamily\color{MSBlue}}
\titleformat*{\subsection}{\large\bfseries\sffamily\color{MSLightBlue}}

%date format
\newdateformat{mydate}{\monthname[\THEMONTH] \THEYEAR}

\fancypagestyle{plain}{%
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
}

\pagestyle{fancy}
\fancyhf{}
\fancyfoot[CO] {\thepage}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

%--------------------------------- Text ----------------------------------
\setcounter{secnumdepth}{0}
\begin{document}
\section{The Algorithms}
In this section we will describe the algorithms we use for each of the placement models.\\
All our algorithms use a quadtree to quickly find all points in an interval. This will be described first. Furthermore, the algorithms for the 2pos model and the 4pos model are very similar, these will be discussed together. Finally, we will describe the algorithm for the 1slider model.

\subsection{Quadtree}

Since advanced label-placing algorithms have a tendency of requesting information about what points exist in a certain area, a quadtree can help speed up those algorithms. A quadtree is defined as a mathematical tree, with a node having four children recursively. Each node of the tree stores information about a certain square-shaped area it bounds, including an array of points which have their location in the area of that node. Nodes which contain points are leaves of the tree. The four child nodes are the subdivision of its parent node. This means that nodes in a certain area can be easily found by traversing the tree.\\
Since every point is distinct, and there are only $10000 * 10000$ possible placements, we can reasonably assume the tree is balanced.\\
\begin{algorithm}[H]
\caption{Add point to the quadtree}
\begin{algorithmic}[1]
\Procedure{AddPoint}{$Point\ p$}
\If{$this.children.size > 0$}\Comment{Here we traverse the tree}
\For{$c \in this.children$}
\If{$Overlap(p, c.area)$}
\State $c.AddPoint(p)$
\EndIf
\EndFor
\Else\Comment{Here add the point to the node}
\State $this.add(p)$
\If{$this.points.size>maxNodeSize$}
\State $this.split()$ \Comment{Split the node into 4 subnodes}
\EndIf
\EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}
In a balanced quadtree the maximum depth is in $O(\log{n})$, which means our algorithm also runs in $O(\log{n}))$

Here we will show how a quadtree can be used to find points in a certain area.\\

\begin{algorithm}[H]
\caption{Find points in an area}
\begin{algorithmic}[1]
\Procedure{PointsInArea}{$Area\ a$}
\State $out = \emptyset$
\If{$this.children.size > 0$}\Comment{Here we traverse the tree}
\For{$c \in this.children$}
\If{$Overlap(a, c.area)$}
\State $out.add(c.PointsInArea())$
\EndIf
\EndFor
\Else\Comment{Here we return the right labels}
\For{$p \in this.points$}
\If{$a.contains(l)$}
\State $out.add(l)$
\EndIf
\EndFor
\EndIf
\State \textbf{return} $out$
\EndProcedure
\end{algorithmic}
\end{algorithm}

When dealing with a balanced quadtree with $n$ points, the worst-case running time is $O(n)$, which is when the PointsInArea method returns all labels. In the worst case scenario, the tree would be traversed for every node. Since we assumed the quadtree to be balanced, there are $O(n)$ nodes, and there are $n$ points, therefore the running time is in $O(n)$.

\subsection{2-position model and 4-position model}
For the 2-position model and the 4-position model we use a simple approach. We will first explain our algorithm and derive its theoretical worst-case running time. Then we will prove that it does not place overlapping labels. In the literature we have found three rules (L1, L2 and L3) [1]. We will describe these rules and show how our algorithm correctly applies L1 and L3. Unfortunately, we learned our algorithm does not apply L2 correctly. We will explain this and provide a possible solution for this.

\subsubsection{Description of the algorithm}
Our algorithm consists of two phases:
\begin{enumerate}
\item \textbf{Phase 1: Mapping the collisions}\\
It checks for every candidate (a candidate is a possible placement of a label for a point) with which candidates it intersects. For each candidate, we store every candidate it collides with in an arraylist, the so-called CollisionList of a candidate. We find these collisions using the quad tree. When we have these collisions, we store all candidates in a minheap. The nodes are the candidates and the keys are their number of collisions plus $\frac{1}{k}$ times the number of candidates its point has. Using this data structure is very useful later on, when we want to extract the minimum very often and change keys of nodes even more frequently.
\item \textbf{Phase 2: Placing candidates}\\
Our actual placement strategy is simple: we find the candidate with the least amount of collisions (with the MinHeap) and we place it. We place a candidate using the Place function. This function takes a candidate $c$ as argument. It will do the following: It will eliminate all the candidates of the point of which $c$ is a candidate and it will also eliminate all the candidates that $c$ collides with (every candidate in $c$'s CollisionList). This eliminating will be done using an Eliminate function. This function takes a candidate $c$ as argument and it will remove $c$ from all the CollisionLists for all candidates $c^*$ in the CollisionList of $c$. It will also remove $c$ from the MinHeap. In this way, later on will not have to look after candidates that are already placed or are eliminated. 
\end{enumerate}
Below you can see the pseudo-code for our algorithm and its running time.

\begin{algorithm}[H]
\caption{2pos and 4pos algorithm}
\begin{algorithmic}[1]
\Procedure{K-Pos-Algorithm}{}\Comment{Can be used for 2pos, 4pos or any k-pos model}
\State Initialize the solution $S$ to the empty set
\State Insert all points in the quad tree $q$
\State Give points their candidates
\ForAll{$c\in$Candidates}\Comment{For each point we will find its collisions}
\State $c.CollisionList\gets$ GiveCollisions($c$)
\EndFor
\State Create a MinHeap $h$ containing all the candidates
\While{$H$ is not empty}
\State $S\gets S\cup \{h.$minimum$\}$\Comment{Add the candidate with the least collisions to the solution}
\State Place($h$.Minimum)\Comment{We place this minimum}
\EndWhile
\State \textbf{return} $S$\Comment{$S$ is our solution, we will return it}
\EndProcedure
\end{algorithmic}
\end{algorithm}
\textbf{Running time}\\
Line 2 takes constant time. Line 3 will take $O(n\log n)$ since it inserts (insertion takes $O(\log n)$) $n$ points. Line 4 has to give $n$ points $k$ candidates. Giving a point a candidate takes $\Theta(1)$. In the case of the 4-position and the 2-position model, $k$ equals 4 and 2 respectively. So this line will take $\Theta(n)$. Now there is the for-loop. This loops over all $\Theta(n)$ candidates and gives it its collisions. The latter takes $O(n)$ since it uses PointsInArea. Now we create a minheap. Creating a heap takes $\Theta(n)$. After that, there is a while-loop. Inside this while-loop we place candidates untill the heap is empty. Placing candidates has running time in the order of the number of eliminations. Every candidate can only be eliminated once and the elimination takes $O(n)$ time. Concluding, the whole algorithm takes $\Theta(1)+\Theta(n\log n)+\Theta(n)+\Theta(n)*O(n)+\Theta(n)+\Theta(n)*O(n)=O(n^2)$.

\subsubsection{Proof of no overlapping labels}
We will prove the correctness (no intersections) of this algorithm using a loop invariant over the while-loop in the main algorithm:

\textbf{Loop invariant:} The set $S$, containing placed candidates, does not contain overlapping candidates. Furthermore, there is no candidate $c_s\in S$ that collides with a candidate $c_h$ in the heap.

\textbf{Initialization:} $S$ is empty initially, so there are no two candidates that overlap each other and there is also no candidate in $S$ that overlaps any of the candidates in the heap.

\textbf{Maintenance:} In every iteration of the while-loop, exactly one candidate $c_m$ is added to $S$. Because of the loop invariant, it has no intersections with any of the candidates that were already in $S$. This proves the maintenance of the first part of the loop invariant. When placing the candidate, we eliminate itself and all its collisions. Calling the Eliminate function on a candidate $c$ will remove $c$ from the minheap. So all candidates in the heap that collide with $c_m$ will be removed from the heap. This together with the second part of the loop invariant (no candidate $c_s\in S$ collides with a candidate $c_h$ in the heap) proves the maintenance of the second part of the loop invariant.

\textbf{Termination:} When the loop is finished, our loop invariant proves that there are no intersecting candidates in $S$.

\subsubsection{Correctly applying the rules}
Our algorithm may look too simple, but in its simplicity lies its elegance. We wanted an algorithm that could place labels efficiently in unclustered areas (using the rules) and also would give a reasonably good solution for clustered areas. This both is done by this very simple approach. Below we will show how our algorithm applies rule L1 and L3 and we will give a possible extension of the algorithm such that it also applies L2 correctly.\\
\\
\textbf{Rule L1}\\
L1 applies if some point $p$ has a candidate $p_i$ without any overlaps. We simply place $p_i$ and eliminate all other candidates of $p$.\\
\\
We will prove that our algorithm places a label on $p$ when L1 occurs. For the sake of contradiction, we will assume no label for $p$ is placed after termination. So $p_i$ must have been eliminated. This only occurs when a candidate of $p$ has been placed (which we assumed is not the case) or when a label has been placed that overlaps $p_i$. The latter cannot happen since $p_i$ has no overlaps. So by contradiction it is proven that if L1 applies for some point $p$, our algorithm will label it.\\
\\
\textbf{Rule L2}\\
L2 applies if some point $p$ has a candidate $p_i$ that only overlaps some candidate $q_k$ of point $q$, and $q$ has another
candidate $q_j$ ($j \neq k$) that is only overlapped by a candidate $p_l$ of $p$ ($l \neq i$). Then $p_i$
and $q_j$ should be added to the solution and all other candidates of $p$ and $q$ should be eliminated.\\
\\
Unfortunately, we found out that our algorithm does not apply L2 correctly in every possible case: suppose L2 applies for two points $p$ and $q$ and futhermore a candidate $q_k$ of $q$ only collides with a candidate $p_i$ of $p$ and $p$ has another candidate $p_l$ ($l\neq i$) which has more than one collision. Then $p_i$, $q_j$ and $q_k$ all have one collision and their points have two candidates. Their keys are thus equal. In this case there is no guarantee that our algorithm does not place $q_k$, eliminating $p_i$, $q_j$ and $q_k$. If this occurs, another label could be placed instead of $p_l$ and thus not labeling $p$, disobeying L2. A quick fix for this problem would be to check whether we are not disobeying L2 everytime we want to place a candidate with one collision. The worst case complexity would not change with this fix. Note that this fix would only improve the algorithm in very, very specific scenario's.\\
\\
\textbf{Rule L3}\\
L3 applies if some point $p$ only has one candidate $p_i$ left and all candidates that intersect with $p$ form a clique. If this is the case, we place $p_i$ and eliminate all its collisions.\\
\\
We will prove that if L3 applies for some point $p$ with candidate $p_i$, then $p_i$ will only be eliminated by applying L3. We will assume $p_i$ is eliminated and then we will prove that L3 has been applied. Since $p_i$ is the only candidate of $p$, it can only be eliminated when placing a colliding candidate $q_j$ of some other point $q$. Since we place the candidate with the lowest key, the key of $q_j$ must be less or equal to the key of $p_i$. $p_i$ and $q_j$ have the same number of collisions since they are in the same clique, so $q$ must have a number of candidates less or equal to that of $p$. $q$ cannot have zero candidates since this would mean there is no $q_j$ so $q$ must have exactly one candidate. This means L3 applied on $q$ and so it is proven that our algorithm correctly applies L3.

\subsection{1-slider algorithm}
% new stuff about L1:
\subsubsection{Overview}
The algorithm we used for the 1-slider model consists of an initialization part and a loop. \\ \\
\textbf{Initialization}\\
Firstly, the 1-slider algorithm initializes the variables we need: the $mostfound$ and $bestsolution$ variables, which will keep track of the best solution so far, and the timer. After that, it initializes a quadtree, filling it with all of the points in the input. Then, each of the points will be assigned a so-called $bounding\ box$, which represent all potential label placements. These $bounding \ boxes$ will be given collision values using the $PointsInArea$ function of the quadtree. After this, a maxheap of points is initialized, using the amount of collisions the $bounding \ box$ of the point has with other $bounding \ boxes$ as keys. \\
\textbf{Loop} \\
Now the algorithm will enter a loop. In this loop, we find a solution for all of the points which have not been $discarded$. Firstly, we have to re-assign collision values for all of the remaining(not $discarded$) points, again using the $PointsInArea$ function of the quadtree. Secondly, we apply rule L1 and L2, which have been explained earlier. Thirdly, we finish the solution by executing a greedy algorithm on the remaining points and then also on all of the points (including the $discarded$ ones). Now, we check whether the solution we found this iteration is better than the best solution so far. If it is better, we replace the previously best solution with this new solution. Now we delete the point of which the $bounding \ box$ has the most collisions from the heap and mark the corresponding point in the quadtree as $discarded$. This loop is repeated until the heap is empty, we have found a solution which places labels on all of the points, or when four and a half minutes have passed. \\ 
In the end, we report the best solution found. \\ 

A detailed explanation of all sub-algorithms and concepts is given below. 

\subsubsection{Reason for deleting the point with most collisions}
The question about this might have arisen by now. We chose to use this kind of loop to further reduce the amount of instances where the greedy part of the algorithm places a label which discards an optimal solution. We might have a case where placing a label according to our greedy rules will overlap a lot of other potential labels. Sometimes placing a label prevents two other labels from being placed, which is suboptimal. Therefore, we try to ignore the labels with the most collisions and keep trying again. In a lot of cases, this finds a better solution.

\subsubsection{Bounding Boxes}
As mentioned earlier, $bounding \ boxes$ represent the outer-most bounds for a label when considering all possible placements using the 1-slider model. Every point $p$ is assigned such a $bounding \ box$. Every $bounding \ box$ $B$ also has a reference to its original point $p$ and a list of $bounding \ boxes$ it intersects with. We use the collision values $x_1$ and $x_2$ for each $bounding \ box$ to determine label placements. The process of assigning these is explained below.

\subsubsection{Giving collisions}
The routine for giving collisions is executed by the quadtree. For each of the points $p$ this function is called on, it checks the xy-area $[p_x - 2*labelwidth, p_x + 2*labelwidth]$ x $[p_y - labelheight, p_y + labelheight]$, using the $PointsInArea$ function of the quadtree. The $bounding \ box$ of the point $p$ collides with the $bounding \ boxes$ of all points in the searched area. This is because points $q$ to the left of $p$ will have $bounding \ boxes$ with right bound $q_x + labelwidth$ and $p$ has left bound $p_x - labelwidth$. If the right bound of $q$ is bigger than the left bound of $p$, so if $q_x + labelwidth > p_x - labelwidth$, then the $bounding \ boxes$ collide. We can rewrite this to $q_x > p_x - 2*labelwidth$, which was the left bound of the x-interval we searched. The other three bounds, to the right, up, and down, work analogously. For each $bounding \ box$ $B$, we put all the $bounding \ boxes$ we find in the list of collisions of $B$. With these lists, we can determine $x_1$ and $x_2$ for each $B$. We do this by initially assigning the left bound of the $B$ as $B_{x_1}$ and the right bound of the $B$ as $B_{x_2}$. After that, we compare the right bound of each $bounding \ box$ in the list of collisions of $B$ to the left of $B$. If this right bound is bigger than $B_{x_1}$, then we make $B_{x_1}$ this new bound, and symmetrically the same with $B_{x_2}$. This way, $x_1$ will be the right-most position for which there are collisions to the left of a point and $x_2$ the left-most point for which there are collisions to the right of a point.

\subsubsection{The heap}
Beside the quadtree, the algorithm also uses a maxheap to store the points. The keys in the maxheap are the amount of collisions the $bounding \ boxes$ of the points have with other $bounding \ boxes$. This way, we can easily remove the point of which the $bounding \ box$ has the most collisions with other $bounding \ boxes$: we simply extract the root of the maxheap in $\Theta(log (k))$ time, with $k$ being the amount of points left in the heap. 

\subsubsection{Implementation of rule L1}
We will now explain how rule L1 is implemented in the 1slider algorithm. Recall that L1 places all labels which can not possibly have any intersections with other labels. We implement this by comparing the found collision values $x_1$ and $x_2$ for each $bounding \ box$ $B$ of each point $p$. If there is enough space in between $x_1$ and $x_2$ to place a label, so if $x_2 - x_1 \geq labelwidth$, then we can be sure that we can place a label there without it ever intersecting any other possible label placement. Therefore, it satisfies L1. We place the label on $p$ with slider value $\frac{p_x - B_{x_1}}{labelwidth} + 1$. This places it with the left bound of the label at x-position $B_{x_1}$.

\subsubsection{Implementation of rule L2}
After L1 is applied, rule L2 is executed. Recall that L2 places labels on two points which have candidates which only collide with each other. To do this, we search for points with $bounding \ boxes$ which have only one collision. We then check whether the $bounding \ boxes$ they collide with also have only one collision. If that is the case, we can say that both $bounding \ boxes$ only have one collision and we have a case of L2. We call the left-most point in this situation $p_1$ and the right-most point $p_2$. If the points have equal x-positions, this is assigned randomly. For each of these cases, we give $p_1$ slider value 0 and the $p_2$ slider value 1. This way, $p_1$ gets a label which is placed all the way to the left and the $p_2$ gets a label which is placed all the way to the right. The two labels will never intersect any labels. They will not intersect each other, because the right bound of the label on $p_1$ will be to the left of the left bound of the label on $p_2$. The labels will also never intersect labels outside of the L2 case, because the $bounding \ boxes$ of these points only collide with each other.

\subsubsection{Why L3 wasn not implemented}
Recall that L3 should be applied whenever there is a clique of intersecting candidates and one of those candidates is the only candidate left for a point. The difficulty when trying to implement this for the 1-slider model is that there is practically an infinite amount of candidates, because of the continuous nature of the slider variable. This means that it will almost never happen that a point only has one possible label placement left. Therefore, L3 will pretty much never occur and it makes little sense to try to implement it into the algorithm.

\subsubsection{Greedy part}
After L1 and L2, we complete the solution by executing a greedy part on the remaining points. We know that L1 and L2 have not placed any labels which are not optimal, but they will not have placed labels on all points where this is possible. Firstly, we do this for all undiscarded points and then we see if there are any discarded points on which we can still place a label.

\subsubsection{Running time}
The running time of this algorithm is dependent on the amount of points $n$ in the input and the total amount of collisions $c$ the $bounding \ boxes$ have. For example, if we find no collisions at all, we have $n$ cases of L1 and the algorithm terminates after the first iteration of the main loop, reporting a solution which places labels on all points. However, for simplicity's sake, we will only give the running time in worst case terms of $n$. \\ \\
\textbf{Initialization}\\
The initialization of the variables we need takes $\Theta(1)$ time. After that, tnitializing the quadtree simply adds every point in the input to the quadtree. Adding a point to the quadtree takes $O(log(n))$ time, so adding every point will take $O(n*log(n))$ time. Now we give each point a bounding box. This takes $\Theta(n)$ time. The time it takes to give collisions to these $bounding \ boxes$ will depend on the amount of points, the size of the labels, and the point distribution. We check  every point, so this gives us a multiplication factor of $n$. When checking every point, we use the function AllPointsInArea of the quadtree. The worst case running time of this function is $O(n)$. The other things we do in this part all depend on how many collisions this function has found, but they take constant time, so the total running time of this part will be $O(n)*O(n)*O(1) = O(n^2)$ worst case. Now, initializing the heap with all of the points takes $O(n)$ time.  \\ \\
 \textbf{The loop} \\
The algorithm now enters the loop. This loop is repeated until the heap is empty, a solution which places labels on all of the points is found, or four and a half minutes have passed. It is nearly impossible to predict when our algorithm will find a solution which places labels on all of the points, so we will not consider this in the running time. Therefore, the total running time of the loop will be the minimum of the time it takes to empty the heap and 4.5 minutes. Firstly, we will determine the time it takes to empty the heap. At the first iteration, the heap contains $n$ points. At the end of each iteration, one point is removed from the heap. Therefore, the loop is repeated $n$ times. Inside the loop, the running time depends on the running time of assinging the collisions, applying L1, applying L2, and executing the greedy part. Most of these steps only use the points which have not been discarded. We will denote this remaining amount of points with $k$. \\ The L1 algorithm checks for every point whether the $bounding \ box$ of that point has enough space in between $x_1$ and $x_2$, and then has the possibility to place a label. These operations take constant time, so the total time it takes to apply L1 is $O(k)$. \\
The L2 algorithm finds all points of which the $bounding \ box$ has only one collision. In the worst case, all of the $bounding \ boxes$ have this, and the algorithm needs to place labels on all of the points. Checking points takes $O(k)$ time. We only do constant time operations every check, so the total time for L2 is $O(k)$. \\
The greedy part will first execute on the points which have not been discarded and then again for all of the discarded points. This means that combined, it will execute on $n$ points every iteration.  
\\ \\
\textbf{Conclusion} \\
So, we execute a loop $n$ times, in which the running times depend on a variable $k$ which runs down from $n$ to 1. The highest rate of growth in the loop is $O(k^2)$. This gives a summation like $\sum_{k=0}^n O(k^2)$, which is equal to $O(n^3)$. We also have the second greedy part, which takes $O(n^2)$. Repeating this $n$ times gives a running time of $O(n^3)$.
The total worst case running time of the complete 1slider algorithm will therefore be $O(n^3) + O(n^3) = O(n^3)$.
\end{document} 